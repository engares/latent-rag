project:
  name: rag_autoencoder_tfm
  version: "0.1"

paths:
  data_dir: "./data/SQUAD"
  checkpoints_dir: "./models/checkpoints"
  logs_dir: "./logs"

embedding_model:
  name: "sentence-transformers/all-MiniLM-L6-v2"
  max_length: 256

models:

# VARIATIONAL AUTOENCODER

  vae:
    input_dim: 384 # S- BERT embedding dimension
    latent_dim: 64 
    hidden_dim: 512
    dataset_file: "squad_vae_embeddings.pt"          
    checkpoint: "vae_text.pth"

# DENOISING AUTOENCODER
  dae:
    input_dim: 384
    latent_dim: 64
    hidden_dim: 512
    dataset_file: "squad_dae_embeddings.pt"
    checkpoint: "dae_text.pth"

# CONTRASTIVE AUTOENCODER
  contrastive:
    input_dim: 384
    latent_dim: 64
    hidden_dim: 512
    dataset_file: "squad_cae_embeddings.pt"
    checkpoint: "contrastive_ae.pth"

data:
  dataset: "squad"            #  "uda"  |  "squad"
  version: "v1"          #  v1, v2  ONly for squad
  max_samples: 2000        #  optional, blankk to use all samples
  include_unanswerable: false   #  Only Squad v2 has this option

training:
  batch_size: 128
  epochs: 50
  learning_rate: 1e-3
  seed: 42
  device: "cuda"  # "cpu"
  deterministic: false      # (true = modo debug)

retrieval:
  backend: faiss          # 'faiss' | 'bruteforce'
  index_type: flatip        # flatip | hnsw | ivfpq
  index_path: ./data/index/faiss_chunks.faiss
  use_gpu: true
  top_k: 10
  max_chunks_per_doc: 3   # (como se defini√≥ en el roadmap de chunking)

generation:
  provider: "openai"       # Just OpenAI by now
  model: "gpt-4o-mini"
  temperature: 0.3
  max_tokens: 256
  system_prompt_path: "./config/prompts/system_prompt.txt"

chunking:
  enabled: false
  mode: semantic        # "sliding" | "semantic"
  max_tokens: 128
  stride: 64
  min_tokens: 48        # solo para 'semantic'
  tokenizer_name: sentence-transformers/all-MiniLM-L6-v2
  index_out: "./data/SQUAD/chunk_index_infer.parquet"
  store_chunk_text: true

evaluation:
  retrieval_metrics: ["Recall@10", "MRR@10", "nDCG@10"] # You can change the k top  simply by changing the @k e.j Recall@10, "MRR@20"
  generation_metrics: ["ROUGE-L", "BLEU"]

logging:
  level: "INFO"
  log_to_file: true
  log_file: "./logs/run.log"
