# LATENT-RAG: Compresión de Embeddings en Sistemas RAG mediante Autoencoders

Este proyecto constituye el código base del Trabajo de Fin de Máster sobre mejora de la eficiencia en sistemas RAG (Retrieval-Augmented Generation) a través de la compresión de embeddings usando distintas variantes de autoencoders (DAE, VAE, Contrastive AE).

## Características principales

* **Entrenamiento de autoencoders** (DAE, VAE, Contrastive AE)
* **Pipeline RAG** completo con generación usando LLMs via API (OpenAI, etc.)
* **Sistema de evaluación** de calidad en tareas de recuperación y generación
* **Compresión configurable** mediante `config.yaml`
* **Descarga automática** y generación de datasets derivados del benchmark UDA

---

## Estructura del proyecto

```
./
├── config/                # Configuraciones globales y prompts
├── data/                  # Procesamiento de datasets y clases PyTorch
├── evaluation/            # Métricas de evaluación
├── generation/            # Generador de respuestas (vía LLM)
├── retrieval/             # Codificadores y recuperación
├── models/                # Implementaciones de autoencoders
├── training/              # Entrenamiento de cada modelo
├── utils/                 # Utilidades compartidas (config, seeds, data)
├── main.py                # Ejecución del pipeline completo
├── requeriments.txt       # Dependencias del entorno
```

## Instalación

```bash
pip install -r requeriments.txt
```

**Nota**: Algunas funcionalidades requieren tener una clave API de OpenAI en un archivo `.env`:

```
OPENAI_API_KEY=sk-xxxxx
```

## Ejecución

### Entrenamiento de un autoencoder:

```bash
python training/train_vae.py --model vae
python training/train_dae.py --model dae
python training/train_cae.py --model contrastive
```

> Los hiperparámetros se definen en `config/config.yaml`. Puedes sobrescribir `--epochs`, `--lr` o `--save_path` desde la línea de comandos.

### Evaluación end-to-end

```bash
python main.py
```

Esto realiza:

1. Carga del modelo y embeddings.
2. Recuperación de documentos.
3. Generación con LLM.
4. Evaluación de recuperación y generación.

---

## Configuración

Archivo: `config/config.yaml`

Define:

* `models`: parámetros específicos para cada autoencoder.
* `training`: batch size, épocas, semilla, dispositivo, `max_samples` (para limitar número de ejemplos).
* `retrieval`: tipo de similitud, top-k, si usar embeddings comprimidos.
* `generation`: proveedor LLM, temperatura, prompt base, etc.

---

## Dataset: UDA (Unsupervised Dense Retrieval for QA)

* Se usa el benchmark `osunlp/uda` vía Huggingface Datasets.
* Se generan dos versiones:

  * `uda_dae_train.jsonl`: para denoising autoencoders
  * `uda_contrastive_train.jsonl`: para contrastive learning
* Se guarda en `./data/`

Si ya existen, se reusan. Si no, se crean automáticamente al lanzar cualquier script de entrenamiento.


---

## Autor

